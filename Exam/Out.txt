=== Gauss-Newton Algorithm on Rosenbrock and Himmelblau ===

Rosenbrock Gauss-Newton:
Minimum at: (1.000. 1.000)
Expected minimum: (1, 1)
Steps taken: 4

Himmelblau Gauss-Newton:
Minimum at: (3.000. 2.000)
Expected minima near: (3, 2), (-2.8, 3.1), (-3.8, -3.3), or (3.6, -1.8)
Steps taken: 3

Although Rosenbrock and Himmelblau functions are not naturally formulated as least-squares problems,
I constructed residual-based formulations to test the Gauss-Newton method in a simplified context.
These tests primarily serve to validate the implementation of the algorithm.
In practice, such problems would typically be solved using Newton's method or quasi-Newton methods,
which are more appropriate for general nonlinear optimization.
Gauss-Newton is best suited for least-squares problems where the objective is a sum of squared residuals,
such as in curve fitting. Therefore, these test cases are somewhat artificial,
but they remain useful for demonstrating convergence behavior and debugging the algorithm.

=== Oscillatory Decay Fit and Comparison ===

Fitting an oscillatory decay function with exponential damping and phase shift is a challenging nonlinear optimization problem,
requiring robust methods to accurately estimate amplitude, decay rate, frequency, and phase from noisy data.
Unlike the Rosenbrock and Himmelblau test functions, this problem naturally fits the least-squares framework,
making it a more appropriate and realistic showcase for the Gauss-Newton method.
Here, the residuals are directly derived from the model fit to data, which aligns with the assumptions behind Gauss-Newton.

Newton method fit parameters:
A     = 118.462
gamma = 0.087
omega = 1.205
phi   = 0.201
Steps taken: 2
sqrt(χ²/N) = 0.114

Gauss-Newton method fit parameters:
A     = 100.581
gamma = 0.074
omega = 1.216
phi   = 1.521
Steps taken: 21
sqrt(χ²/N) = 0.131

Comparison:
The Newton method converged quickly in 2 steps with a lower final χ²,
but it significantly overestimated the amplitude (A = 118.46).
Gauss-Newton required more steps (21), but achieved a more realistic amplitude (A = 100.58),
and correctly fit the damping and frequency. The phase offset was π/2 off,
but this represents the same function up to a shift and is considered valid.
It captures the oscillatory nature of the data better than the Newton method,
specifically after t=15 where the uncertainties are lower and the fit is more reliable.

=== Self-Evaluation ===

In this project, I implemented the Gauss-Newton algorithm for nonlinear least-squares minimization
and tested it on both simple and complex problems. I began by validating the method on residual-based
versions of the Rosenbrock and Himmelblau functions to ensure basic correctness and convergence behavior.

To apply the method to a realistic problem, I tackled the nonlinear fitting of an oscillatory decay model,
which required computing an analytical Jacobian and managing the challenges of fitting multiple interdependent
parameters. To improve stability and convergence, I also extended the implementation with a
Levenberg–Marquardt-style damping mechanism.

Overall, I believe this demonstrates a solid and complete understanding of Gauss-Newton and its application
in both controlled and practical settings. I would assess my work as 9 out of 10, since this is very thorough
but I did not go significantly beyond the core requirements and explore beyond the scope of the assignment.
